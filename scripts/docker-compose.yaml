services:
  mysql:
    image: mysql:8.4.2
    command: --default_authentication_plugin=mysql_native_password
    environment:
      MYSQL_ROOT_PASSWORD: root
    volumes:
      # 设置初始化脚本
      - ./mysql/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "13306:3306"
    healthcheck:
      test: [ "CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "--password=root" ]
      interval: 2s
      timeout: 5s
      retries: 15
      start_period: 10s
    networks:
      default:
  redis:
    image: redis:7.4.0
    command: redis-server --notify-keyspace-events AKE --loadmodule /usr/lib/redis/modules/redisbloom.so
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - '6379:6379'
    networks:
      default:
  kafka:
    image: bitnami/kafka:3.6
    ports:
      - '9092:9092'
      - '9094:9094'
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9094,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
    networks:
      default:
  etcd:
    image: bitnami/etcd:3.4.34
    environment:
      - ALLOW_NONE_AUTHENTICATION=yes
      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379
    ports:
      #      客户端通信接口
      - "2379:2379"
      #      集群节点通信端口
      - "2380:2380"
  prometheus:
    image: prom/prometheus:latest
    volumes:
      #  - 将本地的 prometheus 文件映射到容器内的配置文件
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      #  - 访问数据的端口
      - "9090:9090"
    command:
      - "--web.enable-remote-write-receiver"
      - "--config.file=/etc/prometheus/prometheus.yml"
    extra_hosts:
      - "host.docker.internal:host-gateway"
  grafana:
    image: grafana/grafana-enterprise:11.2.2
    ports:
      - "3000:3000"
  zipkin:
    image: openzipkin/zipkin-slim:3.4
    ports:
      - '9411:9411'
  elasticsearch:
    container_name: elasticsearch
    image: elasticsearch:8.15.5
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      default:
  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    environment:
      - xpack.monitoring.enabled=false
    ports:
      - "5001:5000"
      - "9600:9600"
    volumes:
      #      如果不用filebeat采集日志就需要将日志映射到容器中
      - ../logs:/logs
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    depends_on:
      - elasticsearch
    networks:
      default:
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      default:

volumes:
  esdata:
    driver: local